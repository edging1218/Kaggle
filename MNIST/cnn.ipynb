{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import Data\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size is (42000, 784).\n",
      "Test size is (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "data.data_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "--------------------------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 251.2 MB\n",
      "\n",
      "Test:\n",
      "--------------------------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.data_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "def pd_to_tensor(data_set):\n",
    "    data_set = np.array(data_set)\n",
    "    return np.array([obs.reshape(28, 28, 1) for obs in data_set])\n",
    "\n",
    "def data_preprocess(train, train_target, test):    \n",
    "    train = pd_to_tensor(train)\n",
    "    test = pd_to_tensor(test)\n",
    "    labels = np_utils.to_categorical(np.array(train_target), 10)\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(train, labels, test_size = 0.25, random_state = 1)\n",
    "    return xtrain, xtest, ytrain, ytest, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31500, 28, 28, 1)\n",
      "(10500, 10)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest, test = data_preprocess(data.train, data.train_target, data.test)\n",
    "print xtrain.shape\n",
    "print ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 14, 64)        4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 7, 7, 512)         33280     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_16  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 42,730\n",
      "Trainable params: 42,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, \n",
    "                 kernel_size = 3,\n",
    "                 padding = 'same',\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters = 64, \n",
    "                 kernel_size = 2,\n",
    "                 padding = 'same',\n",
    "                 activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dense(256, activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(Dense(512, \n",
    "                activation = 'relu', \n",
    "                kernel_regularizer=regularizers.l2(0.02)))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 10500 samples\n",
      "Epoch 1/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 2.8248 - acc: 0.6344Epoch 00000: val_loss improved from inf to 2.37849, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 56s - loss: 2.8252 - acc: 0.6343 - val_loss: 2.3785 - val_acc: 0.7162\n",
      "Epoch 2/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 2.0630 - acc: 0.7853Epoch 00001: val_loss improved from 2.37849 to 1.96053, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 55s - loss: 2.0634 - acc: 0.7854 - val_loss: 1.9605 - val_acc: 0.8327\n",
      "Epoch 3/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 1.9547 - acc: 0.8141Epoch 00002: val_loss did not improve\n",
      "31500/31500 [==============================] - 56s - loss: 1.9546 - acc: 0.8141 - val_loss: 2.0143 - val_acc: 0.8072\n",
      "Epoch 4/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 1.9004 - acc: 0.8243Epoch 00003: val_loss improved from 1.96053 to 1.93588, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 56s - loss: 1.9014 - acc: 0.8242 - val_loss: 1.9359 - val_acc: 0.8270\n",
      "Epoch 5/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 1.8693 - acc: 0.8338Epoch 00004: val_loss improved from 1.93588 to 1.90771, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 57s - loss: 1.8689 - acc: 0.8338 - val_loss: 1.9077 - val_acc: 0.8330\n",
      "Epoch 6/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 1.8510 - acc: 0.8372Epoch 00005: val_loss did not improve\n",
      "31500/31500 [==============================] - 58s - loss: 1.8519 - acc: 0.8371 - val_loss: 1.9336 - val_acc: 0.8295\n",
      "Epoch 7/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 1.8362 - acc: 0.8396Epoch 00006: val_loss improved from 1.90771 to 1.84010, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 56s - loss: 1.8361 - acc: 0.8397 - val_loss: 1.8401 - val_acc: 0.8546\n",
      "Epoch 8/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 1.8282 - acc: 0.8436Epoch 00007: val_loss improved from 1.84010 to 1.83390, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 53s - loss: 1.8271 - acc: 0.8437 - val_loss: 1.8339 - val_acc: 0.8586\n",
      "Epoch 9/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 1.8167 - acc: 0.8430Epoch 00008: val_loss did not improve\n",
      "31500/31500 [==============================] - 53s - loss: 1.8161 - acc: 0.8431 - val_loss: 1.8839 - val_acc: 0.8445\n",
      "Epoch 10/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 1.8134 - acc: 0.8467Epoch 00009: val_loss did not improve\n",
      "31500/31500 [==============================] - 54s - loss: 1.8138 - acc: 0.8467 - val_loss: 1.8450 - val_acc: 0.8519\n",
      "Epoch 11/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 1.8022 - acc: 0.8482Epoch 00010: val_loss did not improve\n",
      "31500/31500 [==============================] - 50s - loss: 1.8017 - acc: 0.8483 - val_loss: 1.8520 - val_acc: 0.8480\n",
      "Epoch 12/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 1.7893 - acc: 0.8512Epoch 00011: val_loss did not improve\n",
      "31500/31500 [==============================] - 39s - loss: 1.7888 - acc: 0.8513 - val_loss: 1.8446 - val_acc: 0.8500\n",
      "Epoch 13/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 1.7780 - acc: 0.8533Epoch 00012: val_loss did not improve\n",
      "31500/31500 [==============================] - 39s - loss: 1.7790 - acc: 0.8533 - val_loss: 1.8566 - val_acc: 0.8450\n",
      "Epoch 14/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 1.7713 - acc: 0.8557Epoch 00013: val_loss improved from 1.83390 to 1.83365, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 39s - loss: 1.7718 - acc: 0.8557 - val_loss: 1.8337 - val_acc: 0.8522\n",
      "Epoch 15/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 1.7674 - acc: 0.8563Epoch 00014: val_loss improved from 1.83365 to 1.81096, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 54s - loss: 1.7699 - acc: 0.8562 - val_loss: 1.8110 - val_acc: 0.8606\n",
      "Epoch 16/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 1.7671 - acc: 0.8563Epoch 00015: val_loss did not improve\n",
      "31500/31500 [==============================] - 54s - loss: 1.7676 - acc: 0.8563 - val_loss: 1.8820 - val_acc: 0.8382\n",
      "Epoch 17/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 1.7646 - acc: 0.8564Epoch 00016: val_loss did not improve\n",
      "31500/31500 [==============================] - 54s - loss: 1.7641 - acc: 0.8564 - val_loss: 1.8455 - val_acc: 0.8508\n",
      "Epoch 18/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 1.7594 - acc: 0.8592Epoch 00017: val_loss did not improve\n",
      "31500/31500 [==============================] - 41s - loss: 1.7601 - acc: 0.8591 - val_loss: 1.8316 - val_acc: 0.8509\n",
      "Epoch 19/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 0.8772 - acc: 0.9059Epoch 00018: val_loss improved from 1.81096 to 0.23267, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 39s - loss: 0.8768 - acc: 0.9059 - val_loss: 0.2327 - val_acc: 0.9481\n",
      "Epoch 20/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.2281 - acc: 0.9474Epoch 00019: val_loss did not improve\n",
      "31500/31500 [==============================] - 54s - loss: 0.2282 - acc: 0.9474 - val_loss: 0.2632 - val_acc: 0.9361\n",
      "Epoch 21/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.2230 - acc: 0.9483Epoch 00020: val_loss improved from 0.23267 to 0.19653, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 48s - loss: 0.2229 - acc: 0.9483 - val_loss: 0.1965 - val_acc: 0.9564\n",
      "Epoch 22/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.2138 - acc: 0.9504Epoch 00021: val_loss did not improve\n",
      "31500/31500 [==============================] - 54s - loss: 0.2139 - acc: 0.9504 - val_loss: 0.2029 - val_acc: 0.9550\n",
      "Epoch 23/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9524Epoch 00022: val_loss did not improve\n",
      "31500/31500 [==============================] - 48s - loss: 0.2103 - acc: 0.9522 - val_loss: 0.2031 - val_acc: 0.9530\n",
      "Epoch 24/40\n",
      "31440/31500 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9531Epoch 00023: val_loss did not improve\n",
      "31500/31500 [==============================] - 40s - loss: 0.2040 - acc: 0.9529 - val_loss: 0.2119 - val_acc: 0.9527\n",
      "Epoch 25/40\n",
      "31440/31500 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9533Epoch 00024: val_loss did not improve\n",
      "31500/31500 [==============================] - 40s - loss: 0.1992 - acc: 0.9532 - val_loss: 0.2449 - val_acc: 0.9426\n",
      "Epoch 26/40\n",
      "31440/31500 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9552Epoch 00025: val_loss improved from 0.19653 to 0.17218, saving model to saved_models/weights.best.hdf5\n",
      "31500/31500 [==============================] - 40s - loss: 0.1962 - acc: 0.9552 - val_loss: 0.1722 - val_acc: 0.9638\n",
      "Epoch 27/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9542Epoch 00026: val_loss did not improve\n",
      "31500/31500 [==============================] - 55s - loss: 0.1956 - acc: 0.9542 - val_loss: 0.1923 - val_acc: 0.9589\n",
      "Epoch 28/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.1937 - acc: 0.9560Epoch 00027: val_loss did not improve\n",
      "31500/31500 [==============================] - 51s - loss: 0.1941 - acc: 0.9560 - val_loss: 0.2274 - val_acc: 0.9469\n",
      "Epoch 29/40\n",
      "31440/31500 [============================>.] - ETA: 0s - loss: 0.1896 - acc: 0.9555Epoch 00028: val_loss did not improve\n",
      "31500/31500 [==============================] - 40s - loss: 0.1894 - acc: 0.9555 - val_loss: 0.2038 - val_acc: 0.9535\n",
      "Epoch 30/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.1866 - acc: 0.9581Epoch 00029: val_loss did not improve\n",
      "31500/31500 [==============================] - 40s - loss: 0.1866 - acc: 0.9581 - val_loss: 0.2220 - val_acc: 0.9482\n",
      "Epoch 31/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.1865 - acc: 0.9574Epoch 00030: val_loss did not improve\n",
      "31500/31500 [==============================] - 41s - loss: 0.1865 - acc: 0.9574 - val_loss: 0.1983 - val_acc: 0.9508\n",
      "Epoch 32/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.1824 - acc: 0.9581Epoch 00031: val_loss did not improve\n",
      "31500/31500 [==============================] - 40s - loss: 0.1823 - acc: 0.9582 - val_loss: 0.1956 - val_acc: 0.9540\n",
      "Epoch 33/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9564Epoch 00032: val_loss did not improve\n",
      "31500/31500 [==============================] - 40s - loss: 0.1842 - acc: 0.9565 - val_loss: 0.1955 - val_acc: 0.9570\n",
      "Epoch 34/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9584Epoch 00033: val_loss did not improve\n",
      "31500/31500 [==============================] - 40s - loss: 0.1828 - acc: 0.9584 - val_loss: 0.3402 - val_acc: 0.9150\n",
      "Epoch 35/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9586Epoch 00034: val_loss did not improve\n",
      "31500/31500 [==============================] - 49s - loss: 0.1829 - acc: 0.9587 - val_loss: 0.1811 - val_acc: 0.9590\n",
      "Epoch 36/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9585Epoch 00035: val_loss did not improve\n",
      "31500/31500 [==============================] - 48s - loss: 0.1818 - acc: 0.9585 - val_loss: 0.1870 - val_acc: 0.9571\n",
      "Epoch 37/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 0.1807 - acc: 0.9589Epoch 00036: val_loss did not improve\n",
      "31500/31500 [==============================] - 48s - loss: 0.1806 - acc: 0.9589 - val_loss: 0.1725 - val_acc: 0.9606\n",
      "Epoch 38/40\n",
      "31480/31500 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9593Epoch 00037: val_loss did not improve\n",
      "31500/31500 [==============================] - 43s - loss: 0.1781 - acc: 0.9594 - val_loss: 0.2099 - val_acc: 0.9544\n",
      "Epoch 39/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9585Epoch 00038: val_loss did not improve\n",
      "31500/31500 [==============================] - 42s - loss: 0.1774 - acc: 0.9585 - val_loss: 0.1853 - val_acc: 0.9594\n",
      "Epoch 40/40\n",
      "31460/31500 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9589Epoch 00039: val_loss did not improve\n",
      "31500/31500 [==============================] - 41s - loss: 0.1787 - acc: 0.9589 - val_loss: 0.1771 - val_acc: 0.9585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x115f47ad0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "epochs = 40\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(xtrain, ytrain, \n",
    "          validation_data=(xtest, ytest),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.write_submission(predictions, 'cnn_kernel_k001_a001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
